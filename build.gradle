apply plugin: 'java'
apply plugin: 'scala'

version = '1.0'

if (!hasProperty('against')) {
    ext.against = 'dse'    // default
}
ext {
    scalaVersion = '2.11.12'
    ScalaVersionShort = '2.11'
    SparkVersion = '2.0.2'
    SparkConnectorVersion = '2.0.6'
    Home = System.env.HOME
    DseHome = System.env.DSE_HOME ?: "$Home/dse"
    DseResources = System.env.DSE_RESOURCES ?: "$Home/dse/resources/"
    mainClassName = "com.datastax.sparkstress.SparkCassandraStress"
}

def determineConnectorVersion() {
    if (against == 'dse') {
        def connector = fileTree(dir: "$DseHome", include: '**/spark*connector*jar')
        def connectorJarName = (connector as List)[0].name
        def match = connectorJarName =~ /.*-(\d+\.\d+.\d+).*jar/
        assert match.find(), "Unable to find Spark Cassandra Connector"
        assert match.group(1).length() != 0, "Unable to determine version from " + match.group(0)
        println("Connector Version = " + match.group(1))
        return match.group(1)
    }
    if (against == 'maven') {
        return System.env.CONNECTOR_VERSION ?: SparkConnectorVersion
    }
}

// Parameters for buliding against Maven Libs
def ConnectorVersion = determineConnectorVersion()

// Parameter for building against Connector Repository
def SparkCCHome = System.env.SPARKCC_HOME ?:
        "$Home/repos/spark-cassandra-connector/"

def deps = [
        dse   : {
            println "Using DSE libraries"
            [
                    'dse/lib',
                    'driver/lib',
                    'cassandra/lib',
                    'spark/lib',
                    'shark/lib',
                    'hadoop',
                    'hadoop/lib',
                    'hadoop2-client',
                    'hadoop2-client/lib',
                    'lib',
                    'common',
                    ''
            ].each { dir ->

                provided fileTree(dir: "$DseResources/$dir", include: '*.jar')
            }

            [
                    '/build',
                    '/lib',
                    '/build/lib'
            ].each { dir ->
                provided fileTree(dir: "$DseHome/$dir", include: '*.jar')
            }


        },
        maven : {
            println "Using Maven Libraries"
            compile "com.datastax.spark:spark-cassandra-connector_$ScalaVersionShort:$ConnectorVersion"
            provided "org.apache.spark:spark-core_$ScalaVersionShort:$SparkVersion"
            provided "org.apache.spark:spark-streaming_$ScalaVersionShort:$SparkVersion"
            provided "org.apache.spark:spark-sql_$ScalaVersionShort:$SparkVersion"
        },
        source: {
            println "Using Assembly Jar from Source Repo"

            compile fileTree(dir: "$SparkCCHome/spark-cassandra-connector/target/scala-$ScalaVersionShort/", include: "*.jar")
            provided "org.apache.spark:spark-core_$ScalaVersionShort:$SparkVersion"
            provided "org.apache.spark:spark-streaming_$ScalaVersionShort:$SparkVersion"
            provided "org.apache.spark:spark-sql_$ScalaVersionShort:$SparkVersion"
        },

]

task build_connector(type: Exec) {
    workingDir SparkCCHome
    commandLine 'sbt/sbt', 'clean'
    commandLine 'sbt/sbt', 'assembly'
}

if (against == 'source') {
    jar.dependsOn build_connector
}


jar {
    manifest.attributes("Main-Class": mainClassName)
    baseName = "SparkCassandraStress"
    from {
        (configurations.runtime - configurations.provided).collect {
            it.isDirectory() ? it : zipTree(it)
        }
    } {
        exclude "META-INF/*.SF"
        exclude "META-INF/*.DSA"
        exclude "META-INF/*.RSA"
    }
}

configurations {
    provided
    compile.extendsFrom provided
}


repositories {
    mavenCentral()
}

test {
    if(against == 'dse') {
        exclude '**/NonDseWriteTaskTests/**'
    }
    testLogging {
        events "passed", "skipped", "failed", "standardOut", "standardError"
    }
}

dependencies {
    testCompile group: 'junit', name: 'junit', version: '4.12'
    testCompile "org.scala-lang:scala-library:$scalaVersion"
    testCompile "org.scalatest:scalatest_$ScalaVersionShort:2.2.4"
    compile("org.reflections:reflections:0.9.9") {
        exclude group: 'dom4j', module: 'dom4j'
        exclude group: 'org.javassist', module: 'javassist'
    }
    compile "com.github.scopt:scopt_$ScalaVersionShort:3.2.0"
    compile "joda-time:joda-time:2.8.1"

    println "Checking dependency flag: $against"

}

dependencies deps[(against)]

sourceSets {
    main {
        scala {
            srcDirs = ['src/main/scala', 'src/main/java']
            if (against == 'dse') {
                srcDirs += 'src/dse'
            } else {
                srcDirs += 'src/apache'
            }

            //Api Change Catcher -- This is done to catch the CassandraCount Change in connector 1.2.4
            println(ConnectorVersion)
            def (major, minor, patch) = ConnectorVersion.split(/\./,3).collect { (it.find(/^\d+/).toInteger()) }
            if (major == 1 && minor == 2 && patch < 4){
                println("using special 1.2.0 -1.2.3 stubs")
                srcDirs += 'src/connector/1.2.0to1.2.3'
            } else if (major <= 1 && minor <= 1 ) {
                println("using pre-Connector 1.2.0 stubs")
                srcDirs += 'src/connector/lessThan1.2.0'
            } else { srcDirs += 'src/connector/default' }

        }
    }
}
